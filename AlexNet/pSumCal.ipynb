{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# These three should be changed\n",
    "InChannel = 0\n",
    "\n",
    "# Start and end of output channels\n",
    "OutChannelStart = 0\n",
    "OutChannelEnd = 16\n",
    "\n",
    "# file path filters\n",
    "filterFilePath = './Weights/features.0.weight.pt'\n",
    "\n",
    "# dont't touch\n",
    "N = 16\n",
    "m = 8\n",
    "delt = pow(2,-m)\n",
    "Q = pow(2, N-1) - 1\n",
    "intWeights = torch.load(filterFilePath)\n",
    "floatWeights = intWeights*delt\n",
    "conv = nn.Conv2d(1, OutChannelEnd - OutChannelStart, kernel_size=11, stride=4, padding=0)\n",
    "state_dict = conv.state_dict()\n",
    "a = floatWeights[OutChannelStart:OutChannelEnd,InChannel,:,:]\n",
    "state_dict['weight'] = floatWeights[OutChannelStart:OutChannelEnd,InChannel,:,:].view(state_dict['weight'].size())\n",
    "b = state_dict['weight'][OutChannelStart:OutChannelEnd,InChannel,:,:]\n",
    "state_dict['bias'] = torch.zeros(state_dict['bias'].size())\n",
    "conv.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageSize = 224\n",
    "LargeSize = 227\n",
    "img = torchvision.transforms.ToTensor()(plt.imread('timg.jpg'))\n",
    "img = nn.functional.interpolate(img.view(1,3,650,1200),size=(ImageSize,ImageSize),mode='bilinear')\n",
    "img = (img/delt).to(torch.int16)\n",
    "img = img.to(torch.float) * delt\n",
    "ttt = torch.zeros(1,3,LargeSize,LargeSize)\n",
    "ttt[:,:,2:226,2:226] = img\n",
    "img = ttt\n",
    "output = ((conv(img[:,InChannel,:,:].view(1,1,LargeSize,LargeSize))/delt).to(torch.int16).to(torch.float) * delt).view(-1,55,55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = open(str(InChannel) + '.' + str(OutChannelStart) + '.' + str(OutChannelEnd) + '.outputFloat.csv','w+')\n",
    "strOutputFloat = ''\n",
    "for i in range(len(output[0])):\n",
    "    for j in range(len(output[0])):\n",
    "        for k in range(OutChannelEnd - OutChannelStart):\n",
    "            strOutputFloat += '%.8f, '%(output[k][i][j])\n",
    "    strOutputFloat += '\\n'\n",
    "F.write(strOutputFloat)\n",
    "F.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = open(str(InChannel) + '.' + str(OutChannelStart) + '.' + str(OutChannelEnd) + '.outputInt.csv','w+')\n",
    "strOutputInt = ''\n",
    "for i in range(len(output[0])):\n",
    "    for j in range(len(output[0])):\n",
    "        for k in range(OutChannelEnd - OutChannelStart):\n",
    "            strOutputInt += '%6d, '%(output[k][i][j]/delt)\n",
    "    strOutputInt += '\\n'\n",
    "F.write(strOutputInt)\n",
    "F.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 227, 227])\n"
     ]
    }
   ],
   "source": [
    "intImg = img/delt\n",
    "print intImg.size()\n",
    "F = open('intImg.csv','w+')\n",
    "intImgFile = ''\n",
    "for i in range(227):\n",
    "    for j in range(227):\n",
    "        for k in range(3):\n",
    "            intImgFile += '%6d, '%(intImg[0][k][i][j])\n",
    "    intImgFile += '\\n'\n",
    "F.write(intImgFile)\n",
    "F.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Findings\n",
    "\n",
    "Padding 2 in the front and padding 1 in the back, making an 224 x 224 image 227 x 227\n",
    "is the same as padding 2 in both side to make it 228 x 228 when filter is 11 x 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print (output1 != output3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1289, -0.4492, -0.7891,  ..., -0.8945, -0.4180, -1.0195],\n",
      "        [-1.3945, -0.3750,  0.5742,  ..., -0.6719,  0.2188, -0.5273],\n",
      "        [-0.6562, -0.4922, -0.5312,  ..., -0.6953,  0.3320, -0.5938],\n",
      "        ...,\n",
      "        [-0.5586,  1.1250, -0.3438,  ..., -1.2500,  0.7031,  0.5781],\n",
      "        [-0.6094,  0.2148, -0.4102,  ..., -0.9102,  0.3633,  0.9414],\n",
      "        [-0.6523, -0.1016, -0.6016,  ...,  0.1797,  0.8359,  1.3281]])\n"
     ]
    }
   ],
   "source": [
    "print output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1289, -0.4492, -0.7891,  ..., -0.8945, -0.4180, -1.0195],\n",
      "        [-1.3945, -0.3750,  0.5742,  ..., -0.6719,  0.2188, -0.5273],\n",
      "        [-0.6562, -0.4922, -0.5312,  ..., -0.6953,  0.3320, -0.5938],\n",
      "        ...,\n",
      "        [-0.5586,  1.1250, -0.3438,  ..., -1.2500,  0.7031,  0.5781],\n",
      "        [-0.6094,  0.2148, -0.4102,  ..., -0.9102,  0.3633,  0.9414],\n",
      "        [-0.6523, -0.1016, -0.6016,  ...,  0.1797,  0.8359,  1.3281]])\n"
     ]
    }
   ],
   "source": [
    "print output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1289, -0.4492, -0.7891,  ..., -0.8945, -0.4180, -1.0195],\n",
      "        [-1.3945, -0.3750,  0.5742,  ..., -0.6719,  0.2188, -0.5273],\n",
      "        [-0.6562, -0.4922, -0.5312,  ..., -0.6953,  0.3320, -0.5938],\n",
      "        ...,\n",
      "        [-0.5586,  1.1250, -0.3438,  ..., -1.2500,  0.7031,  0.5781],\n",
      "        [-0.6094,  0.2148, -0.4102,  ..., -0.9102,  0.3633,  0.9414],\n",
      "        [-0.6523, -0.1016, -0.6016,  ...,  0.1797,  0.8359,  1.3281]])\n"
     ]
    }
   ],
   "source": [
    "print output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2695, -0.2695, -0.1719,  ..., -0.8164, -0.2578, -0.6328],\n",
      "        [-0.8750, -0.3438,  0.7422,  ..., -0.5664,  0.2070, -0.3633],\n",
      "        [-0.2852, -0.5195, -0.6719,  ..., -0.3672,  0.2891, -0.4453],\n",
      "        ...,\n",
      "        [ 0.1523,  0.6641, -0.6328,  ..., -0.8320,  0.9414,  0.3750],\n",
      "        [-0.2344,  0.0391, -0.6953,  ..., -0.6484,  0.5625,  0.9375],\n",
      "        [ 0.2305,  0.4141,  0.1250,  ...,  0.8867,  1.5000,  1.4297]])\n"
     ]
    }
   ],
   "source": [
    "print output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (py2env)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
