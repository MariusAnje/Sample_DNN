{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HappyDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        data = self.data.iloc[idx, 0:].values\n",
    "        data = torch.Tensor(data.astype('float'))\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        inputs = data[0:2]\n",
    "        labels = data[2:4]\n",
    "        return inputs, labels\n",
    "\n",
    "happy = HappyDataset(csv_file='happy.csv')\n",
    "\n",
    "dataloader = DataLoader(happy, batch_size=1,\n",
    "                        shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class float_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(float_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = float_Net().cuda().half()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25045776367\n",
      "0.694946289062\n",
      "0.521945953369\n",
      "0.338481903076\n",
      "0.153614044189\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    tLoss = 0\n",
    "    for index, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        labels = labels.cuda().half()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs.cuda().half())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tLoss += loss.item()\n",
    "    if i%100 == 0:\n",
    "        print tLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2232])\n",
      "tensor([0.7540])\n",
      "tensor([0.9612])\n",
      "tensor([0.1101])\n"
     ]
    }
   ],
   "source": [
    "print net(torch.Tensor([0,0])).data\n",
    "print net(torch.Tensor([0,1])).data\n",
    "print net(torch.Tensor([1,0])).data\n",
    "print net(torch.Tensor([1,1])).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oSample(torch.autograd.Function):\n",
    "    def __init__(ctx, M, N):\n",
    "        ctx.delt = pow(2,-M)\n",
    "        ctx.max = pow(2,N) - 1\n",
    "    def forward(ctx, inputs):\n",
    "        S = (inputs/ctx.delt).round()\n",
    "        S[S>=ctx.max] = ctx.max\n",
    "        S[S<-ctx.max] = -ctx.max - 1\n",
    "        return S\n",
    "    def backward(ctx, g):\n",
    "        return g\n",
    "\n",
    "class oCut(torch.autograd.Function):\n",
    "    def __init__(ctx, M, N):\n",
    "        ctx.delt = pow(2,-M)\n",
    "        ctx.max = pow(2,N) - 1\n",
    "    def forward(ctx, inputs):\n",
    "        S = (inputs*ctx.delt).round()\n",
    "        S[S>=ctx.max] = ctx.max\n",
    "        S[S<-ctx.max] = -ctx.max - 1\n",
    "        return S\n",
    "    def backward(ctx, g):\n",
    "        return g\n",
    "\n",
    "class oRound(torch.autograd.Function):\n",
    "    def __init__(ctx, M, N):\n",
    "        ctx.max = pow(2,N) - 1\n",
    "    def forward(ctx, inputs):\n",
    "        S = inputs.round()\n",
    "        S[S>=ctx.max] = ctx.max\n",
    "        S[S<-ctx.max] = -ctx.max - 1\n",
    "        return S\n",
    "    def backward(ctx, g):\n",
    "        return g\n",
    "\n",
    "def sampleStateDict(net):\n",
    "    Dict = net.state_dict()\n",
    "    Key = Dict.keys()\n",
    "    for i in Key:\n",
    "        Dict[i] = oSample(5,8)(Dict[i])\n",
    "    net.load_state_dict(Dict)\n",
    "\n",
    "def protectStateDict(net):\n",
    "    Dict = net.state_dict()\n",
    "    Key = Dict.keys()\n",
    "    for i in Key:\n",
    "        Dict[i] = Dict[i]*1\n",
    "    return Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 5\n",
    "N = 8\n",
    "class sample_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sample_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = oCut(M,N)(self.fc1(oSample(M,N)(x)))\n",
    "        #print x\n",
    "        x = oRound(M,N)(F.relu(x))\n",
    "        x = oCut(M,N)(self.fc2(x))*pow(2,-M)\n",
    "        return x\n",
    "\n",
    "sample_net = sample_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0312])\n",
      "tensor([0.0938])\n",
      "tensor([0.0625])\n",
      "tensor([0.1562])\n"
     ]
    }
   ],
   "source": [
    "TMP = protectStateDict(sample_net)\n",
    "sampleStateDict(sample_net)\n",
    "print sample_net(torch.Tensor([0,0])).data\n",
    "print sample_net(torch.Tensor([0,1])).data\n",
    "print sample_net(torch.Tensor([1,0])).data\n",
    "print sample_net(torch.Tensor([1,1])).data\n",
    "sample_net.load_state_dict(TMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001953125\n",
      "0.001953125\n",
      "0.001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12377:\n",
      "Traceback (most recent call last):\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 85, in _worker_loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1013, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 170, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 491, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 51, in ismodule\n",
      "    def ismodule(object):\n",
      "  File \"/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 37718) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    torch.set_num_threads(1)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2893\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yanzy/Envs/fp/local/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(sample_net.parameters(), lr=0.0001)\n",
    "a = time.time()\n",
    "for i in range(1000):\n",
    "    tLoss = 0\n",
    "    for index, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        TMP = protectStateDict(sample_net)\n",
    "        sampleStateDict(sample_net)\n",
    "        outputs = sample_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        sample_net.load_state_dict(TMP)\n",
    "        optimizer.step()\n",
    "        tLoss += loss.item()\n",
    "    if tLoss == 0:\n",
    "        break\n",
    "    if i%100 == 5:\n",
    "        print tLoss\n",
    "b = time.time()\n",
    "print b - a \n",
    "TMP = protectStateDict(sample_net)\n",
    "sampleStateDict(sample_net)\n",
    "print sample_net(torch.Tensor([0,0])).data\n",
    "print sample_net(torch.Tensor([0,1])).data\n",
    "print sample_net(torch.Tensor([1,0])).data\n",
    "print sample_net(torch.Tensor([1,1])).data\n",
    "sample_net.load_state_dict(TMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
